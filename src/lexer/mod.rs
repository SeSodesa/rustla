/// This is the `lexer` module of ruSTLa

mod token;
mod state;
mod token_mappings;
mod tests;
mod error;

use std::fmt;

use crate::lexer::token::{Token, TokenType};
use crate::lexer::state::{State};
use crate::lexer::error::{TokenizeError, LexError};

#[derive(PartialEq)]
pub struct Lexer {
  source: String,
  state: State,
  actions: token_mappings::LexerActions,
  tokens: Vec<Token>,
  buffer: String,
  lexeme_start: usize,
  lookahead: usize,
  row: usize,
  col: usize,
}

impl fmt::Debug for Lexer {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
      f.debug_struct("Lexer")
        .field("lexeme_start", &self.source)
        .field("buffer", &self.buffer)
        .finish()
  }
}

impl fmt::Display for Lexer {
  fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
    write!(f, "Lexer location: row = {}, col = {}", self.row, self.col)
  }
}

/// Lexer type methods
impl Lexer {

  /// ### Lexer constructor
  pub fn new(source: String) -> Lexer {
    Lexer {
      source: source,
      state: State::Body,
      actions: token_mappings::lexer_actions(),
      tokens: Vec::new(),
      buffer: String::with_capacity(4096),
      lexeme_start: 0,
      lookahead: 0,
      row:0,
      col: 0,
    }
  }

  /// ### lex
  /// Pushes the tokens generated by
  /// `scan_token` to `Lexer.tokens`
  /// Consumes the Lexer.
  fn lex(self) { // -> Result<Vec<Token>, LexError>

    let mut char_iter = self.source
      .chars();

    while let Some(c) = char_iter.next() {
      self.scan_token();
    } 

  }

  /// ### tokenize_buffer
  /// Tries to match the contents of the buffer
  /// with the regexes found in the regex
  /// submodule. If a match is found,
  /// `Some<Token>` of matching type is returned.
  fn tokenize_buffer(&self) { // -> Some<Token> {

  }

  /// ### scan_token
  /// Reads the next lexeme and produces
  /// a token mathcing it. This is the
  /// core of the lexer itself.
  fn scan_token(&self) {
    
  }


  /// ### advance
  /// Reads the next character
  /// (unicode scalar, not grapheme cluster!)
  /// in the source.
  fn advance(&mut self) -> Option<char>{

    self.lookahead += 1;

    let c: char = self.source
    .chars()
    .nth(self.lookahead - 1)?;

    Some(c)
  }

  /// ### is_at_eof
  /// A function that checks whether all
  /// of the characters in the current file
  /// have been consumed.
  pub fn is_at_eof(&self) -> bool {
    self.lookahead >= self.source.chars().count()
  }

}
